<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="MOVIN enables real-time motion caputre using a single LiDAR sensor.">
  <meta name="keywords" content="Motion capture, Generative-AI, LiDAR">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MOVIN: Real-time motion capture using a single LiDAR sensor</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->
  <link rel="icon" href="static/images/TTibu1.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">MOVIN: Real-time Motion Capture using a Single LiDAR</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://dk-jang.github.io">Deok-Kyeong Jang</a><sup>* 1,2</sup>, </span>
            <span class="author-block">
              <a href="https://linkedin.com/in/dongseok-yang-868045203">Dongseok Yang</a><sup>* 1,2</sup>, </span>
            <span class="author-block">
              <a href="https://linkedin.com/in/deok-yun-jang-a2851b161">Deok-Yun Jang</a><sup>* 1,2</sup>, </span>
            <span class="author-block">
              <a href="https://linkedin.com/in/byeol2ya">Byeoli Choi</a><sup>* 1,2</sup>, </span>
            <span class="author-block">
              <a href="https://lava.kaist.ac.kr/?page_id=41">Sung-Hee Lee</a><sup>2</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup><a href="https://www.movin3d.com">MOVIN Inc. </a>, </span>
            <span class="author-block"><sup>2</sup>KAIST</span>
          </div>
          <div class="is-size-6 contribution">
            <span class="author-block"><sup>*</sup>Equal contribution</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2309.09314"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://youtu.be/C0o8Hz4FFTk"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/MOVIN3D/movin_pg2023"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code & Data</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video> -->
      <img src="./static/images/movin_teaser.png"/>
      <h2 class="subtitle has-text-centered">
        Our MOVIN framework enables real-time full-body motion capture with global translation from 3D LiDAR point cloud.
      </h2>
    </div>
  </div>
</section>

<!-- 
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Recent advancements in technology have brought forth new forms of interactive applications, such as the social metaverse, where end users interact with each other through their virtual avatars. In such applications, precise full-body tracking is essential for an immersive experience and a sense of embodiment with the virtual avatar. However, current motion capture systems are not easily accessible to end users due to their high cost, the requirement for special skills to operate them, or the discomfort associated with wearable devices.
            In this paper, we present MOVIN, the data-driven generative method for real-time motion capture with global tracking, using a single LiDAR sensor. Our autoregressive conditional variational autoencoder (CVAE) model learns the distribution of pose variations conditioned on the given 3D point cloud from LiDAR. 
          </p>
          <p>
            As a central factor for high-accuracy motion capture, we propose a novel feature encoder to learn the correlation between the historical 3D point cloud data and global, local pose features, resulting in effective learning of the pose prior. Global pose features include root translation, rotation, and foot contacts, while local features comprise joint positions and rotations.
          </p>
          <p>
            Subsequently, a pose generator takes into account the sampled latent variable along with the features from the previous frame to generate a plausible current pose.
            Our framework accurately predicts the performer's 3D global information and local joint details while effectively considering temporally coherent movements across frames. We demonstrate the effectiveness of our architecture through quantitative and qualitative evaluations, comparing it against state-of-the-art methods. Additionally, we implement a real-time application to showcase our method in real-world scenarios.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Overall architecture -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
          <h2 class="title is-3">Overall framework</h2>
          <img src="./static/images/overview.png"/>
          <div class="content has-text-justified">
            <p>
              Overview of MOVIN framework. 
              The model separates into the Feature Encoder and the Pose Generator. 
              At inference time, only the Pose Generator and the embedding modules of Feature Encoder are used. 
              Given the sampled point cloud sequence, our model generates current global and local pose features, which is used as a condition the next time frame.
            </p>
          </div>
      </div>
    </div>
    <!--/ Overall architecture. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/C0o8Hz4FFTk"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <!-- Concurrent Work. -->
    <br/>
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Equipment setup</h2>
        <div class="content has-text-justified">
          <p>
            Equipment setup for LiDAR based markerless real-time motion capture using our solution.
            We only need one laptop to process the incoming LiDAR signal and generate output motion aligned with the 3D point cloud data.
          </p>
        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->

    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <img src="./static/images/setup.JPG"/>
        </div>
      </div>

      <div class="column">
        <div class="content">
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/setup.MOV"
                    type="video/mp4">
          </video>
          <div class="content has-text-justified">
            <p>
              Users simply mount a single LiDAR sensor in front of themselves and can perform any action they desire.
            </p>
          </div>
        </div>
      </div>
    </div>

    <!-- Animation. -->
    <br/>
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Results</h2>

        <!-- Interpolating. -->
        <!-- <h3 class="title is-4">Live real-time motion capture</h3>
        <div class="content has-text-justified">
          <p>
            Our real-time motion capture system with a single LiDAR.
            Our system does not require offline calibration and captures the subject’s motion in real-time, allowing users to check the results immediately. 
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_start.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>Start Frame</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info"
                   id="interpolation-slider"
                   step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_end.jpg"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold">End Frame</p>
          </div>
        </div>
        <br/> -->
        <!--/ Interpolating. -->

        <!-- Live-stream. -->
        <h3 class="title is-4">Live real-time motion capture</h3>
        <div class="content has-text-justified">
          <p>
            Our real-time motion capture system with a single LiDAR.
            Our system does not require offline calibration and captures the subject’s motion in real-time, allowing users to check the results immediately. 
          </p>
        </div>
        <div class="content has-text-centered">
          <!-- <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="75%">
            <source src="./static/videos/replay.mp4"
                    type="video/mp4">
          </video> -->
          <video id="live_stream" autoplay controls muted loop playsinline height="100%">
            <source src="static/videos/live_stream.mp4"
                    type="video/mp4">
          </video>
        </div>
        <!--/ Live-stream. -->

        <!-- comparison. -->
        <!-- <br/>
        <h3 class="title is-4">Comparison with SOTA methods</h3>
        <div class="content has-text-justified">
          <p>
            To validate the effectiveness of our method, we compare our results with the state-of-the-art methods, 
            VIBE and MotionBERT, which are vision-based methods.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="75%">
            <source src="./static/videos/replay.mp4"
                    type="video/mp4">
          </video>
          <video id="live_stream" autoplay controls muted loop playsinline width="85%">
            <source src="static/videos/live_stream.mp4"
                    type="video/mp4">
          </video>
        </div> -->
        <!--/ comparison. -->

      </div>
    </div>
    <!--/ Animation. -->

    <!-- Concurrent Work. -->
    <br/>
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-4">Comparison with SOTA methods</h2>
        <div class="content has-text-justified">
          <p>
            To validate the effectiveness of our method, we compare our results with the state-of-the-art methods, 
            VIBE and MotionBERT, which are vision-based methods. <b>All results were not post-processed to ensure a fair comparison.</b>
          </p>
        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->


    <div class="columns is-centered">
      
      <!-- Visual Effects. -->
      <div class="column">
        <div class="content">
          <p>
            <b>* Subject 1: 170cm</b>
          </p>
          <video id="comparison1_1" autoplay controls muted loop playsinline height="100%">
            <source src="static/videos/comparison1_1.mp4"
                    type="video/mp4">
          </video>
          <div class="content has-text-centered">
            <p>
              Locomotion.
            </p>
          </div>
          <video id="comparison1" autoplay controls muted loop playsinline height="100%">
            <source src="static/videos/comparison1_2.mp4"
                    type="video/mp4">
          </video>
          <div class="content has-text-centered">
            <p>
              Static.
            </p>
          </div>
        </div>
      </div>
      <!--/ Visual Effects. -->

      <!-- Matting. -->
      <div class="column">
        <div class="columns is-centered">
          <div class="column content">
            <p>
              <b>* Subject 2: 162cm</b>
            </p>
            <video id="comparison2_1" autoplay controls muted loop playsinline height="100%">
              <source src="static/videos/comparison2_1.mp4"
                      type="video/mp4">
            </video>
            <div class="content has-text-centered">
              <p>
                Locomotion.
              </p>
            </div>
            <video id="comparison2)2" autoplay controls muted loop playsinline height="100%">
              <source src="static/videos/comparison2_2.mp4"
                      type="video/mp4">
            </video>
            <div class="content has-text-centered">
              <p>
                Static.
              </p>
            </div>
          </div>
        </div>
      </div>
      <!--/ Matting. -->
    </div>


    <!-- Concurrent Work. -->
    <br/>
    <br/>
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            If you are interested in AI-powered markerless LiDAR based motion capture, check out our website, <a href="https://www.movin3d.com">MOVIN, Inc.</a>
          </p>
        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <!-- <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre> -->
    <pre><code>@misc{jang2023movin,
      title={MOVIN: Real-time Motion Capture using a Single LiDAR}, 
      author={Deok-Kyeong Jang and Dongseok Yang and Deok-Yun Jang and Byeoli Choi and Taeil Jin and Sung-Hee Lee},
      year={2023},
      eprint={2309.09314},
      archivePrefix={arXiv},
      primaryClass={cs.GR}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <!-- <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div> -->
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            It is based on the <a href="https://github.com/nerfies/nerfies.github.io">Nerfies website</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
